{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 33551,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 28083,
          "modelId": 39106
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebookc17cf95adf",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredcs/llama/blob/main/llama3-ft-local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install -U transformers\n",
        "%pip install -U datasets\n",
        "%pip install -U accelerate\n",
        "%pip install -U peft\n",
        "%pip install -U trl\n",
        "%pip install -U bitsandbytes\n",
        "%pip install -U wandb"
      ],
      "metadata": {
        "trusted": true,
        "id": "_oPLa0pGplou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    prepare_model_for_kbit_training,\n",
        "    get_peft_model,\n",
        ")\n",
        "import os, torch, wandb\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, setup_chat_format\n"
      ],
      "metadata": {
        "id": "VLzgZ14X_rMs",
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:05.609602Z",
          "iopub.execute_input": "2024-05-20T06:41:05.609974Z",
          "iopub.status.idle": "2024-05-20T06:41:16.077875Z",
          "shell.execute_reply.started": "2024-05-20T06:41:05.609945Z",
          "shell.execute_reply": "2024-05-20T06:41:16.076739Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
        "login(token = hf_token)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:16.080163Z",
          "iopub.execute_input": "2024-05-20T06:41:16.080982Z",
          "iopub.status.idle": "2024-05-20T06:41:16.293854Z",
          "shell.execute_reply.started": "2024-05-20T06:41:16.080942Z",
          "shell.execute_reply": "2024-05-20T06:41:16.292835Z"
        },
        "trusted": true,
        "id": "EAi1_7G6plov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wb_token = user_secrets.get_secret(\"wandb\")\n",
        "\n",
        "wandb.login(key=wb_token)\n",
        "run = wandb.init(\n",
        "    project='Fine-tune Llama 3 8B on Medical Dataset',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ],
      "metadata": {
        "id": "na9CAoHC5gM9",
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:16.29514Z",
          "iopub.execute_input": "2024-05-20T06:41:16.295474Z",
          "iopub.status.idle": "2024-05-20T06:41:35.725239Z",
          "shell.execute_reply.started": "2024-05-20T06:41:16.295445Z",
          "shell.execute_reply": "2024-05-20T06:41:35.723764Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
        "dataset_name = \"ruslanmv/ai-medical-chatbot\"\n",
        "new_model = \"llama-3-8b-chat-doctor\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:35.72829Z",
          "iopub.execute_input": "2024-05-20T06:41:35.728705Z",
          "iopub.status.idle": "2024-05-20T06:41:36.13982Z",
          "shell.execute_reply.started": "2024-05-20T06:41:35.728666Z",
          "shell.execute_reply": "2024-05-20T06:41:36.138491Z"
        },
        "trusted": true,
        "id": "4TnWd02Oplow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set torch dtype and attention implementation\n",
        "if torch.cuda.get_device_capability()[0] >= 8:\n",
        "    !pip install -qqq flash-attn\n",
        "    torch_dtype = torch.bfloat16\n",
        "    attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "    attn_implementation = \"eager\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:36.141686Z",
          "iopub.execute_input": "2024-05-20T06:41:36.142115Z",
          "iopub.status.idle": "2024-05-20T06:41:36.638052Z",
          "shell.execute_reply.started": "2024-05-20T06:41:36.142071Z",
          "shell.execute_reply": "2024-05-20T06:41:36.636812Z"
        },
        "trusted": true,
        "id": "ck01tiIGplow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QLoRA config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch_dtype,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=attn_implementation\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "StJKGiDDHzdk",
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:36.639439Z",
          "iopub.execute_input": "2024-05-20T06:41:36.640377Z",
          "iopub.status.idle": "2024-05-20T06:41:53.108511Z",
          "shell.execute_reply.started": "2024-05-20T06:41:36.640331Z",
          "shell.execute_reply": "2024-05-20T06:41:53.107445Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA config\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
        ")\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:53.109946Z",
          "iopub.execute_input": "2024-05-20T06:41:53.110339Z",
          "iopub.status.idle": "2024-05-20T06:41:54.3239Z",
          "shell.execute_reply.started": "2024-05-20T06:41:53.110299Z",
          "shell.execute_reply": "2024-05-20T06:41:54.322698Z"
        },
        "trusted": true,
        "id": "XEHhHwfRplow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "dataset = load_dataset(dataset_name, split=\"all\")\n",
        "dataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n",
        "\n",
        "def format_chat_template(row):\n",
        "    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n",
        "               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n",
        "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
        "    return row\n",
        "\n",
        "dataset = dataset.map(\n",
        "    format_chat_template,\n",
        "    num_proc= 4,\n",
        ")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "XzF2UjPvTBag",
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:54.325629Z",
          "iopub.execute_input": "2024-05-20T06:41:54.326026Z",
          "iopub.status.idle": "2024-05-20T06:41:56.149302Z",
          "shell.execute_reply.started": "2024-05-20T06:41:54.325985Z",
          "shell.execute_reply": "2024-05-20T06:41:56.148317Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['text'][3]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:56.151833Z",
          "iopub.execute_input": "2024-05-20T06:41:56.153117Z",
          "iopub.status.idle": "2024-05-20T06:41:56.684481Z",
          "shell.execute_reply.started": "2024-05-20T06:41:56.153079Z",
          "shell.execute_reply": "2024-05-20T06:41:56.683457Z"
        },
        "trusted": true,
        "id": "34i17Tz3plow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:56.688873Z",
          "iopub.execute_input": "2024-05-20T06:41:56.689303Z",
          "iopub.status.idle": "2024-05-20T06:41:57.081227Z",
          "shell.execute_reply.started": "2024-05-20T06:41:56.689267Z",
          "shell.execute_reply": "2024-05-20T06:41:57.079903Z"
        },
        "trusted": true,
        "id": "_4PfuOgOplox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamter\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=new_model,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=0.2,\n",
        "    logging_steps=1,\n",
        "    warmup_steps=10,\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=2e-4,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    group_by_length=True,\n",
        "    report_to=\"wandb\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "peOnLAAhS0y1",
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:57.083146Z",
          "iopub.execute_input": "2024-05-20T06:41:57.083973Z",
          "iopub.status.idle": "2024-05-20T06:41:57.438807Z",
          "shell.execute_reply.started": "2024-05-20T06:41:57.083931Z",
          "shell.execute_reply": "2024-05-20T06:41:57.437711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting sft parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= 512,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:57.440137Z",
          "iopub.execute_input": "2024-05-20T06:41:57.440439Z",
          "iopub.status.idle": "2024-05-20T06:41:59.100147Z",
          "shell.execute_reply.started": "2024-05-20T06:41:57.44041Z",
          "shell.execute_reply": "2024-05-20T06:41:59.099012Z"
        },
        "trusted": true,
        "id": "nCdDr_Kyplox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T06:41:59.101637Z",
          "iopub.execute_input": "2024-05-20T06:41:59.102Z",
          "iopub.status.idle": "2024-05-20T07:11:59.304646Z",
          "shell.execute_reply.started": "2024-05-20T06:41:59.101964Z",
          "shell.execute_reply": "2024-05-20T07:11:59.303642Z"
        },
        "trusted": true,
        "id": "8-wgBl3kplox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.model.save_pretrained(new_model)\n",
        "wandb.finish()\n",
        "model.config.use_cache = True"
      ],
      "metadata": {
        "id": "nKgZBEGVS5a2",
        "execution": {
          "iopub.status.busy": "2024-05-20T07:11:59.306038Z",
          "iopub.execute_input": "2024-05-20T07:11:59.30643Z",
          "iopub.status.idle": "2024-05-20T07:12:06.731536Z",
          "shell.execute_reply.started": "2024-05-20T07:11:59.306399Z",
          "shell.execute_reply": "2024-05-20T07:12:06.730608Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.model.save_pretrained(new_model)\n",
        "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T07:12:06.732721Z",
          "iopub.execute_input": "2024-05-20T07:12:06.733015Z",
          "iopub.status.idle": "2024-05-20T07:12:13.713453Z",
          "shell.execute_reply.started": "2024-05-20T07:12:06.732987Z",
          "shell.execute_reply": "2024-05-20T07:12:13.712397Z"
        },
        "trusted": true,
        "id": "sJIT-ZhFplox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"}]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n",
        "\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(text.split(\"assistant\")[1])"
      ],
      "metadata": {
        "id": "L7vHP41ITQPb",
        "execution": {
          "iopub.status.busy": "2024-05-20T07:31:05.339483Z",
          "iopub.execute_input": "2024-05-20T07:31:05.340238Z",
          "iopub.status.idle": "2024-05-20T07:31:23.404642Z",
          "shell.execute_reply.started": "2024-05-20T07:31:05.340201Z",
          "shell.execute_reply": "2024-05-20T07:31:23.403516Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I always feel weak, can you help me with that?\"}]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n",
        "\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(text.split(\"assistant\")[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-20T07:32:09.028266Z",
          "iopub.execute_input": "2024-05-20T07:32:09.029038Z",
          "iopub.status.idle": "2024-05-20T07:32:27.88394Z",
          "shell.execute_reply.started": "2024-05-20T07:32:09.028986Z",
          "shell.execute_reply": "2024-05-20T07:32:27.882857Z"
        },
        "trusted": true,
        "id": "Egjk__dPplox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}